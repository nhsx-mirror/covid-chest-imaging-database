# Helper tools for the infrastructure

## Log download

The `get_logs.py` script helps with the download and collation of log fragments
for logs generated by the various loader pipelines.

```shell
$ ./get_logs.py --help
usage: get_logs.py [-h] [-g GROUP_NAME] [-s STREAM_NAME] [-o OUTPUT_FILE]

Get a whole log stream with all the fragments from AWS.

optional arguments:
  -h, --help            show this help message and exit
  -g GROUP_NAME, --group-name GROUP_NAME
                        The name of the log group to use.
  -s STREAM_NAME, --stream-name STREAM_NAME
                        The log stream name to get. By default the latest stream is queried and downloaded.
  -o OUTPUT_FILE, --output-file OUTPUT_FILE
                        File to save the log results to.
```

## Batch deletion from a versioned bucket

It's occasionally necessary to delete multiple files from the warehouse buckets.
Those buckets are versioned, and thus can be quite a bit of effort to delete things.

The `batchdelete.py` tool helps query a list of files or for a given prefix, and also
possible to run deletion for all file versions for that list or prefix.

```shell
$ ./batchdelete.py --help
usage: batchdelete.py [-h] --bucket BUCKET [--infile INFILE] [--prefix PREFIX] [--versionsfile VERSIONSFILE] [--delete] [--workers WORKERS]

Delete files from S3

optional arguments:
  -h, --help            show this help message and exit
  --bucket BUCKET       The bucket to query/delete from.
  --infile INFILE       The file containing the list of objects/prefixes to query or delete.
  --prefix PREFIX       The prefix to list all files in and optionally delete.
  --versionsfile VERSIONSFILE
                        A file with key,versionid listing to delete, generated by the querying of this script.
  --delete              Acutally try to delete after querying
  --workers WORKERS     Number of parallel workers when getting versions from an 'infile'
```
